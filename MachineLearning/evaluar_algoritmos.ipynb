{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                     # Tratamiento de datos\n",
    "import matplotlib.pyplot as plt                         # Graficos\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold     # Clases desequelibradas\n",
    "from sklearn.metrics import precision_score, f1_score, accuracy_score, recall_score\n",
    "import statistics                                       # Estadistica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Profesores</th>\n",
       "      <th>Puntuacion</th>\n",
       "      <th>Recomiendad</th>\n",
       "      <th>Dificultad</th>\n",
       "      <th>Etiqueta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>OCOTITLA ROJAS NANCY</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.35</td>\n",
       "      <td>3.6</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CHAVARRIA BAEZ LORENA</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>5.3</td>\n",
       "      <td>malo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>RODRIGUEZ SARABIA TANIA</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.8</td>\n",
       "      <td>bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ZAGAL FLORES ROBERTO ESWART</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>3.3</td>\n",
       "      <td>bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CATALAN SALGADO EDGAR ARMANDO</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.48</td>\n",
       "      <td>4.2</td>\n",
       "      <td>malo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                     Profesores  Puntuacion  Recomiendad   \n",
       "0         NaN           OCOTITLA ROJAS NANCY         4.8         0.35  \\\n",
       "1         NaN          CHAVARRIA BAEZ LORENA         6.0         0.45   \n",
       "2         NaN        RODRIGUEZ SARABIA TANIA         5.2         0.42   \n",
       "3         NaN    ZAGAL FLORES ROBERTO ESWART         8.0         0.90   \n",
       "4         NaN  CATALAN SALGADO EDGAR ARMANDO         5.5         0.48   \n",
       "\n",
       "   Dificultad Etiqueta  \n",
       "0         3.6  regular  \n",
       "1         5.3     malo  \n",
       "2         1.8    bueno  \n",
       "3         3.3    bueno  \n",
       "4         4.2     malo  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_excel(\"datosProfesores.xlsx\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rasgos y clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.iloc[:, 2:5].values\n",
    "y = dataset.iloc[:, 5].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Desvalance de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+]Maximo: 36 \n",
      "[+]Minimo: 22\n"
     ]
    }
   ],
   "source": [
    "# --> Contar cuantos valores hay por clase\n",
    "valores_por_clase = dataset['Etiqueta'].value_counts()\n",
    "\n",
    "# --> Buscar el valor mas grande y el mas pequeño\n",
    "print(f\"[+]Maximo: {max(valores_por_clase)} \\n[+]Minimo: {min(valores_por_clase)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+]Desbalanceado\n"
     ]
    }
   ],
   "source": [
    "ir = 36/22\n",
    "print(\"[+]Desbalanceado\" if ir > 1.5 else \"[+]Balanceado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy=\"auto\", k_neighbors=5)\n",
    "x, y = smote.fit_resample(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regular    36\n",
      "malo       36\n",
      "bueno      36\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "clases_balanceadas = pd.Series(y).value_counts()\n",
    "print(clases_balanceadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo a evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos de validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exactitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+]Exactitud: 55.55555555555556 %\n",
      "[+]Desviación estandar: 12.638125740085918 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(SVC(), x, y, cv=10, scoring='accuracy')\n",
    "print(f\"[+]Exactitud: {100 * scores.mean()} %\")\n",
    "print(f\"[+]Desviación estandar: {100 * scores.std()} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validación cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[+]Exactitud:\t 55.55555555555556 %\n",
      "[+]Presicion:\t 47.51587301587302 %\n",
      "[+]F1-score:\t 45.01948051948052 %\n",
      "[+]Sensibilidad: 49.722222222222214 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\uriel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\uriel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\uriel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\uriel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\uriel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# --> Lista de metricas\n",
    "lista_exactitud = []\n",
    "lista_precison = []\n",
    "lista_f1score = []\n",
    "lista_sensibilidad = []\n",
    "\n",
    "# --> Objeto para validacion\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# ------------| Método de validación k-fold  cross-validation |------------\n",
    "# --> Iteraciones\n",
    "for entramiento, prueba in skf.split(x, y):\n",
    "    # --> Separar datos en entrenamiento y prueba\n",
    "    x_entrenamiento = [x[z] for z in entramiento]\n",
    "    x_prueba = [x[z] for z in prueba]\n",
    "\n",
    "    y_entrenamiento = [y[z] for z in entramiento]\n",
    "    y_prueba = [y[z] for z in prueba]\n",
    "\n",
    "    # --> Entrenar modelo y predecir\n",
    "    y_predicha=SVC().fit(x_entrenamiento, y_entrenamiento).predict(x_prueba)\n",
    "\n",
    "    # --> Metricas\n",
    "    lista_exactitud.append(accuracy_score(y_prueba, y_predicha))\n",
    "    lista_precison.append(precision_score(y_prueba, y_predicha, average=\"macro\"))\n",
    "    lista_f1score.append(f1_score(y_prueba, y_predicha, average=\"macro\"))\n",
    "    lista_sensibilidad.append(recall_score(y_prueba, y_predicha, average=\"macro\"))\n",
    "\n",
    "print(f\"\"\"\n",
    "[+]Exactitud:\\t {100*(statistics.mean(lista_exactitud))} %\n",
    "[+]Presicion:\\t {100*(statistics.mean(lista_precison))} %\n",
    "[+]F1-score:\\t {100*(statistics.mean(lista_f1score))} %\n",
    "[+]Sensibilidad: {100*(statistics.mean(lista_sensibilidad))} %\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parámetros óptimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+]Mejor exactitud: 59.28571428571428 %\n",
      "[+]Mejores parametros: {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# --> Parametros a evaluar\n",
    "parametros = [\n",
    "    {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "    {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.5, 0.1, 0.01, 0.001, 0.0001]}\n",
    "    ]\n",
    "\n",
    "# --> Objeto de busqueda\n",
    "busqueda = GridSearchCV(estimator=SVC(), param_grid=parametros, scoring='accuracy', cv=skf)\n",
    "\n",
    "# --> Entrenamiento\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, test_size=0.2)\n",
    "\n",
    "busqueda.fit(x_train, y_train)\n",
    "\n",
    "# --> Resultados\n",
    "print(f\"[+]Mejor exactitud: {100*busqueda.best_score_} %\")\n",
    "print(f\"[+]Mejores parametros: {busqueda.best_params_}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
